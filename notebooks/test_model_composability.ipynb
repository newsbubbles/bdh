{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§© Testing BDH's Model Composability Claim\n",
    "\n",
    "One of the most interesting claims from Adrian Kosowski:\n",
    "\n",
    "> \"You can concatenate trained BDH models and they just work.\"\n",
    "\n",
    "This would be remarkable - normally you can't just combine neural networks!\n",
    "\n",
    "## Why This Might Work in BDH\n",
    "\n",
    "1. **Sparse activations**: Only ~5% of neurons active, so less interference\n",
    "2. **Positive activations**: No cancellation between positive/negative\n",
    "3. **Monosemantic neurons**: Each neuron = one concept, so concepts from different models don't clash\n",
    "\n",
    "## What We'll Test\n",
    "\n",
    "1. Train two models on different domains\n",
    "2. Concatenate their latent spaces\n",
    "3. See if the combined model retains both capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip install torch datasets matplotlib tqdm -q\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo if needed\n",
    "import os\n",
    "if not os.path.exists('bdh.py'):\n",
    "    !git clone https://github.com/newsbubbles/bdh.git temp_bdh\n",
    "    !cp temp_bdh/bdh.py .\n",
    "    !rm -rf temp_bdh\n",
    "\n",
    "from bdh import BDH, BDHConfig\n",
    "print('BDH loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Create Two Specialized Datasets\n",
    "\n",
    "We'll train one model on English prose and another on Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialized datasets\n",
    "\n",
    "# Dataset 1: English prose patterns\n",
    "prose_samples = [\n",
    "    \"The quick brown fox jumps over the lazy dog. \",\n",
    "    \"In the beginning, there was nothing but darkness. \",\n",
    "    \"She walked through the garden, admiring the flowers. \",\n",
    "    \"The old man sat by the fire, telling stories of his youth. \",\n",
    "    \"Rain fell softly on the roof, creating a gentle rhythm. \",\n",
    "    \"The city lights twinkled in the distance like stars. \",\n",
    "    \"He opened the book and began to read aloud. \",\n",
    "    \"The waves crashed against the shore, endless and eternal. \",\n",
    "    \"Morning came with the sound of birds singing. \",\n",
    "    \"The forest was quiet, save for the rustling leaves. \",\n",
    "] * 100  # Repeat for more data\n",
    "\n",
    "# Dataset 2: Python code patterns\n",
    "code_samples = [\n",
    "    \"def hello(): print('Hello, World!') \",\n",
    "    \"for i in range(10): x += i \",\n",
    "    \"if x > 0: return True \",\n",
    "    \"class MyClass: def __init__(self): pass \",\n",
    "    \"import numpy as np; arr = np.zeros(10) \",\n",
    "    \"def fib(n): return n if n < 2 else fib(n-1) + fib(n-2) \",\n",
    "    \"with open('file.txt') as f: data = f.read() \",\n",
    "    \"try: result = x / y except: result = 0 \",\n",
    "    \"lambda x: x * 2 \",\n",
    "    \"[x**2 for x in range(10) if x % 2 == 0] \",\n",
    "] * 100\n",
    "\n",
    "# Convert to byte tensors\n",
    "prose_text = ' '.join(prose_samples)\n",
    "code_text = ' '.join(code_samples)\n",
    "\n",
    "prose_data = torch.tensor([b for b in prose_text.encode('utf-8')], dtype=torch.long)\n",
    "code_data = torch.tensor([b for b in code_text.encode('utf-8')], dtype=torch.long)\n",
    "\n",
    "print(f'Prose data: {len(prose_data):,} bytes')\n",
    "print(f'Code data: {len(code_data):,} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Train Two Specialized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, name, steps=1000, batch_size=32, block_size=128):\n",
    "    \"\"\"Train a BDH model on specific data.\"\"\"\n",
    "    config = BDHConfig(\n",
    "        n_layer=3,\n",
    "        n_embd=128,\n",
    "        n_head=4,\n",
    "        mlp_internal_dim_multiplier=32,\n",
    "        dropout=0.1\n",
    "    )\n",
    "    model = BDH(config).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    losses = []\n",
    "    pbar = tqdm(range(steps), desc=f'Training {name}')\n",
    "    \n",
    "    for step in pbar:\n",
    "        # Random batch\n",
    "        idx = torch.randint(0, len(data) - block_size - 1, (batch_size,))\n",
    "        x = torch.stack([data[i:i+block_size] for i in idx]).to(device)\n",
    "        y = torch.stack([data[i+1:i+block_size+1] for i in idx]).to(device)\n",
    "        \n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits.view(-1, 256), y.view(-1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            pbar.set_postfix({'loss': f'{np.mean(losses[-100:]):.4f}'})\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train prose model\n",
    "print('Training prose model...')\n",
    "prose_model, prose_losses = train_model(prose_data, 'Prose')\n",
    "print(f'Final prose loss: {np.mean(prose_losses[-50:]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train code model\n",
    "print('Training code model...')\n",
    "code_model, code_losses = train_model(code_data, 'Code')\n",
    "print(f'Final code loss: {np.mean(code_losses[-50:]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(prose_losses, alpha=0.3, color='blue')\n",
    "ax.plot(np.convolve(prose_losses, np.ones(50)/50, mode='valid'), color='blue', label='Prose')\n",
    "ax.plot(code_losses, alpha=0.3, color='red')\n",
    "ax.plot(np.convolve(code_losses, np.ones(50)/50, mode='valid'), color='red', label='Code')\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Specialized Models')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Evaluate Specialization\n",
    "\n",
    "Verify each model is specialized to its domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_data(model, data, n_samples=100, block_size=128):\n",
    "    \"\"\"Evaluate model loss on data.\"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            idx = torch.randint(0, len(data) - block_size - 1, (1,))\n",
    "            x = data[idx:idx+block_size].unsqueeze(0).to(device)\n",
    "            y = data[idx+1:idx+block_size+1].unsqueeze(0).to(device)\n",
    "            \n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, 256), y.view(-1))\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    return np.mean(losses), np.std(losses)\n",
    "\n",
    "# Cross-evaluation\n",
    "print('Cross-evaluation (lower is better):')\n",
    "print()\n",
    "\n",
    "prose_on_prose, _ = evaluate_on_data(prose_model, prose_data)\n",
    "prose_on_code, _ = evaluate_on_data(prose_model, code_data)\n",
    "code_on_prose, _ = evaluate_on_data(code_model, prose_data)\n",
    "code_on_code, _ = evaluate_on_data(code_model, code_data)\n",
    "\n",
    "print(f'                  | Prose Data | Code Data')\n",
    "print(f'------------------|------------|----------')\n",
    "print(f'Prose Model       | {prose_on_prose:.4f}     | {prose_on_code:.4f}')\n",
    "print(f'Code Model        | {code_on_prose:.4f}     | {code_on_code:.4f}')\n",
    "print()\n",
    "\n",
    "# Check specialization\n",
    "prose_specialized = prose_on_prose < prose_on_code\n",
    "code_specialized = code_on_code < code_on_prose\n",
    "\n",
    "if prose_specialized and code_specialized:\n",
    "    print('âœ“ Both models are specialized to their domains!')\n",
    "else:\n",
    "    print('âš  Models may not be sufficiently specialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Compose Models\n",
    "\n",
    "Now the key test: can we combine these models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComposedBDH(nn.Module):\n",
    "    \"\"\"\n",
    "    Compose two BDH models by concatenating their latent spaces.\n",
    "    \n",
    "    The idea: since BDH uses sparse, positive activations,\n",
    "    we can concatenate the encoder outputs and let the\n",
    "    combined sparse representation work together.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_a, model_b, mode='concat_latent'):\n",
    "        super().__init__()\n",
    "        self.model_a = model_a\n",
    "        self.model_b = model_b\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Share embedding (both models have same vocab)\n",
    "        # Use model_a's embedding\n",
    "        \n",
    "        # For output, we need to combine predictions\n",
    "        # Option 1: Average logits\n",
    "        # Option 2: Learn a combiner\n",
    "        # Option 3: Weighted average\n",
    "        \n",
    "        self.combine_weight = nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get predictions from both models\n",
    "        logits_a = self.model_a(x)\n",
    "        logits_b = self.model_b(x)\n",
    "        \n",
    "        # Combine predictions\n",
    "        w = torch.sigmoid(self.combine_weight)\n",
    "        combined_logits = w * logits_a + (1 - w) * logits_b\n",
    "        \n",
    "        return combined_logits\n",
    "\n",
    "# Create composed model\n",
    "composed_model = ComposedBDH(prose_model, code_model).to(device)\n",
    "print('Created composed model (simple averaging)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More sophisticated composition: merge at the layer level\n",
    "class DeepComposedBDH(nn.Module):\n",
    "    \"\"\"\n",
    "    Deeper composition: concatenate encoder outputs at each layer.\n",
    "    \n",
    "    This tests the claim that sparse BDH representations can be\n",
    "    combined without interference.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_a, model_b):\n",
    "        super().__init__()\n",
    "        self.model_a = model_a\n",
    "        self.model_b = model_b\n",
    "        \n",
    "        # Freeze original models\n",
    "        for p in self.model_a.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.model_b.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # Learn to combine\n",
    "        n_embd = model_a.config.n_embd\n",
    "        self.combiner = nn.Linear(n_embd * 2, n_embd)\n",
    "        self.output_proj = nn.Linear(n_embd, 256)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get embeddings from both\n",
    "        h_a = self.model_a.embedding(x)\n",
    "        h_b = self.model_b.embedding(x)\n",
    "        \n",
    "        # Process through layers\n",
    "        for layer_a, layer_b in zip(self.model_a.layers, self.model_b.layers):\n",
    "            h_a = layer_a(h_a)\n",
    "            h_b = layer_b(h_b)\n",
    "        \n",
    "        # Combine final representations\n",
    "        h_combined = torch.cat([h_a, h_b], dim=-1)\n",
    "        h_out = self.combiner(h_combined)\n",
    "        \n",
    "        # Project to vocabulary\n",
    "        logits = self.output_proj(h_out)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Create deep composed model\n",
    "deep_composed = DeepComposedBDH(prose_model, code_model).to(device)\n",
    "print('Created deep composed model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Evaluate Composed Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate simple composed model (no training)\n",
    "print('Simple Composed Model (averaging, no training):')\n",
    "composed_on_prose, _ = evaluate_on_data(composed_model, prose_data)\n",
    "composed_on_code, _ = evaluate_on_data(composed_model, code_data)\n",
    "print(f'  Prose: {composed_on_prose:.4f} (specialist: {prose_on_prose:.4f})')\n",
    "print(f'  Code:  {composed_on_code:.4f} (specialist: {code_on_code:.4f})')\n",
    "print()\n",
    "\n",
    "# Check if composed model is good at both\n",
    "prose_ok = composed_on_prose < (prose_on_prose + code_on_prose) / 2\n",
    "code_ok = composed_on_code < (prose_on_code + code_on_code) / 2\n",
    "\n",
    "if prose_ok and code_ok:\n",
    "    print('âœ“ Composed model works reasonably on both domains!')\n",
    "else:\n",
    "    print('~ Composed model needs fine-tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the deep composed model on mixed data\n",
    "print('Fine-tuning deep composed model on mixed data...')\n",
    "\n",
    "# Create mixed dataset\n",
    "mixed_data = torch.cat([prose_data, code_data])\n",
    "\n",
    "# Only train the combiner layers\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [p for p in deep_composed.parameters() if p.requires_grad],\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "finetune_losses = []\n",
    "for step in tqdm(range(500), desc='Fine-tuning'):\n",
    "    idx = torch.randint(0, len(mixed_data) - 129, (32,))\n",
    "    x = torch.stack([mixed_data[i:i+128] for i in idx]).to(device)\n",
    "    y = torch.stack([mixed_data[i+1:i+129] for i in idx]).to(device)\n",
    "    \n",
    "    logits = deep_composed(x)\n",
    "    loss = F.cross_entropy(logits.view(-1, 256), y.view(-1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    finetune_losses.append(loss.item())\n",
    "\n",
    "print(f'Fine-tuning complete. Final loss: {np.mean(finetune_losses[-50:]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fine-tuned composed model\n",
    "print('\\nFine-tuned Deep Composed Model:')\n",
    "deep_on_prose, _ = evaluate_on_data(deep_composed, prose_data)\n",
    "deep_on_code, _ = evaluate_on_data(deep_composed, code_data)\n",
    "print(f'  Prose: {deep_on_prose:.4f}')\n",
    "print(f'  Code:  {deep_on_code:.4f}')\n",
    "print()\n",
    "\n",
    "# Compare all models\n",
    "print('='*60)\n",
    "print('COMPARISON SUMMARY')\n",
    "print('='*60)\n",
    "print()\n",
    "print(f'                    | Prose Data | Code Data | Avg')\n",
    "print(f'--------------------|------------|-----------|-------')\n",
    "print(f'Prose Specialist    | {prose_on_prose:.4f}     | {prose_on_code:.4f}    | {(prose_on_prose+prose_on_code)/2:.4f}')\n",
    "print(f'Code Specialist     | {code_on_prose:.4f}     | {code_on_code:.4f}    | {(code_on_prose+code_on_code)/2:.4f}')\n",
    "print(f'Simple Composed     | {composed_on_prose:.4f}     | {composed_on_code:.4f}    | {(composed_on_prose+composed_on_code)/2:.4f}')\n",
    "print(f'Deep Composed (FT)  | {deep_on_prose:.4f}     | {deep_on_code:.4f}    | {(deep_on_prose+deep_on_code)/2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "models = ['Prose\\nSpecialist', 'Code\\nSpecialist', 'Simple\\nComposed', 'Deep\\nComposed']\n",
    "prose_scores = [prose_on_prose, code_on_prose, composed_on_prose, deep_on_prose]\n",
    "code_scores = [prose_on_code, code_on_code, composed_on_code, deep_on_code]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, prose_scores, width, label='Prose Data', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, code_scores, width, label='Code Data', color='coral')\n",
    "\n",
    "ax.set_ylabel('Loss (lower is better)')\n",
    "ax.set_title('Model Composability Test')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.2f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3), textcoords='offset points',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('composability_test.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Test Generation from Composed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, prompt, max_new=100, temperature=0.8):\n",
    "    \"\"\"Generate text from a prompt.\"\"\"\n",
    "    model.eval()\n",
    "    tokens = torch.tensor([[b for b in prompt.encode('utf-8')]], dtype=torch.long, device=device)\n",
    "    \n",
    "    for _ in range(max_new):\n",
    "        # Get prediction for last position\n",
    "        with torch.no_grad():\n",
    "            logits = model(tokens[:, -128:])  # Use last 128 tokens\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        \n",
    "        tokens = torch.cat([tokens, next_token], dim=1)\n",
    "    \n",
    "    return bytes(tokens[0].cpu().tolist()).decode('utf-8', errors='replace')\n",
    "\n",
    "# Test generation\n",
    "print('='*60)\n",
    "print('GENERATION TEST')\n",
    "print('='*60)\n",
    "\n",
    "# Prose prompt\n",
    "prose_prompt = \"The old man\"\n",
    "print(f'\\nProse prompt: \"{prose_prompt}\"')\n",
    "print(f'Prose model: {generate(prose_model, prose_prompt, max_new=50)}')\n",
    "print(f'Composed:    {generate(deep_composed, prose_prompt, max_new=50)}')\n",
    "\n",
    "# Code prompt\n",
    "code_prompt = \"def hello\"\n",
    "print(f'\\nCode prompt: \"{code_prompt}\"')\n",
    "print(f'Code model:  {generate(code_model, code_prompt, max_new=50)}')\n",
    "print(f'Composed:    {generate(deep_composed, code_prompt, max_new=50)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('BDH MODEL COMPOSABILITY CLAIM VERDICT')\n",
    "print('='*70)\n",
    "print()\n",
    "\n",
    "# Calculate metrics\n",
    "specialist_avg = (prose_on_prose + code_on_code) / 2\n",
    "composed_avg = (deep_on_prose + deep_on_code) / 2\n",
    "\n",
    "# Composed should be close to specialist average\n",
    "composability_ratio = composed_avg / specialist_avg\n",
    "\n",
    "print(f'Specialist average loss: {specialist_avg:.4f}')\n",
    "print(f'Composed model loss:     {composed_avg:.4f}')\n",
    "print(f'Ratio: {composability_ratio:.2f}x')\n",
    "print()\n",
    "\n",
    "if composability_ratio < 1.2:\n",
    "    print('âœ“ CLAIM SUPPORTED: Composed model performs nearly as well as specialists!')\n",
    "    print('  BDH models can be effectively combined.')\n",
    "elif composability_ratio < 1.5:\n",
    "    print('~ PARTIALLY SUPPORTED: Composed model works but with some degradation.')\n",
    "    print('  Composition is possible but not seamless.')\n",
    "else:\n",
    "    print('âœ— CLAIM NOT WELL SUPPORTED: Significant degradation when composing.')\n",
    "    print('  Models do not combine as cleanly as claimed.')\n",
    "\n",
    "print()\n",
    "print('Note: This is a simplified test. The original claim may refer to')\n",
    "print('more sophisticated composition methods or larger models.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}